{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597800790398",
   "display_name": "Python 3.8.3 32-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import random\n",
    "import math\n",
    "import scipy\n",
    "from scipy import linalg\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data \n",
    "def Data():\n",
    "    # membaca data\n",
    "    file_name = 'datasets.xlsx'\n",
    "    data_training = pd.read_excel(file_name, sheet_name='training', usecols=range(1, 14))\n",
    "    data_testing = pd.read_excel(file_name, sheet_name='testing', usecols=range(1, 14))\n",
    "    train_target = pd.read_excel(file_name, sheet_name='training', usecols=[14])\n",
    "    test_target = pd.read_excel(file_name, sheet_name='testing', usecols=[14])\n",
    "\n",
    "    # mengubah data dalam bentuk matriks\n",
    "    Data.dt_training = data_training.to_numpy()\n",
    "    Data.dt_testing = data_testing.to_numpy()\n",
    "    Data.dt_target_training = train_target.to_numpy()\n",
    "    Data.dt_target_testing = test_target.to_numpy()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hidden_layer(input_weights, biases, n_hidden_node, data_input):\n",
    "    # inisialisasi input weight\n",
    "    input_weight = input_weights.reshape(n_hidden_node, 13)\n",
    "\n",
    "    # inisialisasi bias\n",
    "    bias = biases\n",
    "\n",
    "    # transpose input weight\n",
    "    transpose_input_weight = np.transpose(input_weight)\n",
    "\n",
    "    # matriks output hidden layer\n",
    "    hidden_layer = []\n",
    "    for data in range(len(data_input)):\n",
    "\n",
    "        # perkalian data input dengan input weight transpose\n",
    "        h = np.matmul(data_input[data], transpose_input_weight)\n",
    "        \n",
    "        # penambahan dengan bias\n",
    "        h_output = np.add(h, bias)\n",
    "        hidden_layer.append(h_output)\n",
    "    \n",
    "    return hidden_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aktivasi hasil keluaran hidden layer\n",
    "def Activation(hidden_layer):\n",
    "    for row in range(len(hidden_layer)):\n",
    "        for col in range(len(hidden_layer[row])):\n",
    "            hidden_layer[row][col] = 1 / (1 + np.exp((hidden_layer[row][col] * (-1))))\n",
    "    activation = hidden_layer\n",
    "    \n",
    "    return activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matriks moore penrose pseudo-inverse menggunakan SVD\n",
    "def Pseudoinverse(hidden_layer):\n",
    "    h_pseudo_inverse = scipy.linalg.pinv2(hidden_layer, cond=None, rcond=None, return_rank=False, check_finite=True)\n",
    "    \n",
    "    return h_pseudo_inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# menghitung output weight\n",
    "def Output_weight(pseudo_inverse, target):\n",
    "    beta = np.matmul(pseudo_inverse, target)\n",
    "    \n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# menghitung hasil prediksi pada data testing\n",
    "def Target_output(testing_hidden_layer, output_weight):\n",
    "    target = np.matmul(testing_hidden_layer, output_weight)\n",
    "    # memetakan matriks target pada klasifikasi\n",
    "    prediction = []\n",
    "    for result in range(len(target)):\n",
    "        dist_target_0 = abs(target[result] - 0)\n",
    "        dist_target_1 = abs(target[result] - 1)\n",
    "        min_dist = min(dist_target_0, dist_target_1)\n",
    "        if min_dist == dist_target_0:\n",
    "            predict = 0\n",
    "        elif min_dist == dist_target_1:\n",
    "            predict = 1\n",
    "        prediction.append(predict)\n",
    "        \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inisialisasi partikel / posisi partikel (input weight & bias)\n",
    "def Particle(n_inputWeights, n_biases):\n",
    "    # inisialisasi input weight\n",
    "    input_weights = []\n",
    "    for input_weight in range(0, n_inputWeights):\n",
    "        input_weights.append(round(random.uniform(-1.0, 1.0), 2))\n",
    "\n",
    "    # inisialisasi bias\n",
    "    biases = []\n",
    "    for bias in range(0, n_biases):\n",
    "        biases.append(round(random.random(), 2))\n",
    "\n",
    "    return input_weights + biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inisialisasi kecepatan awal \n",
    "def Velocity_0(n_particles):\n",
    "    return [0] * n_particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluasi akurasi\n",
    "def Evaluate(actual, prediction):\n",
    "    true = 0\n",
    "    for i in range(min(len(actual), len(prediction))):\n",
    "        if actual[i] == prediction[i]:\n",
    "            true += 1\n",
    "    # akurasi\n",
    "    accuracy = round(((true / len(prediction)) * 100), 2) \n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mendapatkan pBest\n",
    "def Pbest(particles, fitness):\n",
    "    fitness = np.expand_dims(fitness, axis=1)\n",
    "    pbest = np.hstack((particles, fitness))\n",
    "    \n",
    "    return pbest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# membandingkan pbest ke t dan pbest ke t+1\n",
    "def Comparison(pbest_t, pbest_t_1):\n",
    "    for i in range(min(len(pbest_t), len(pbest_t_1))):\n",
    "        if pbest_t[i][-1] > pbest_t_1[i][-1]:\n",
    "            pbest_t_1[i] = pbest_t[i]\n",
    "        else:\n",
    "            pbest_t_1[i] = pbest_t_1[i]\n",
    "    \n",
    "    return pbest_t_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mendapatkan partikel terbaik dalam suatu populasi\n",
    "def Gbest(particles, fitness):\n",
    "    # fitness / akurasi terbaik\n",
    "    best_fitness = np.amax(fitness)\n",
    "    \n",
    "    # partikel dengan fitness terbaik\n",
    "    particle = fitness.index(best_fitness)\n",
    "    best_particle = particles[particle]\n",
    "\n",
    "    # gbest\n",
    "    gbest = np.hstack((best_particle, best_fitness))\n",
    "\n",
    "    return gbest  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update kecepatan\n",
    "def Velocity_update(pbest, gbest, w, c1, c2, particles, velocity):\n",
    "\n",
    "    # mencari batas tiap fitur\n",
    "    interval = []\n",
    "    for i in range(len(particles[0])):\n",
    "        x_max = np.amax(np.array(particles)[:, i])\n",
    "        x_min = np.amin(np.array(particles)[:, i])\n",
    "        k = round(random.random(), 1)\n",
    "        v_max_i = np.array(((x_max - x_min)/2) * k)\n",
    "        v_min_i = np.array(v_max_i * -1)\n",
    "        intvl = np.hstack((v_min_i, v_max_i))\n",
    "        interval.append(intvl)\n",
    "\n",
    "    # update kecepatan\n",
    "    r1 = round(random.random(), 1)\n",
    "    r2 = round(random.random(), 1)\n",
    "    for i in range(min(len(particles), len(velocity), len(pbest), len(gbest))):\n",
    "        for j in range(min(len(particles[i]) - 1, len(pbest[i]) - 1)):\n",
    "            velocity[i] = (w * velocity[i]) + (c1 * r1 * (pbest[i][j] - particles[i][j])) + (c2 * r2 * (gbest[i] - particles[i][j]))\n",
    "    \n",
    "    return velocity\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update posisi partikel\n",
    "def Position_update(current_position, velocity_update):\n",
    "    for i in range(min(len(current_position), len(velocity_update))):\n",
    "        for j in range(len(current_position[i])):\n",
    "            current_position[i][j] = (current_position[i][j] + velocity_update[i])\n",
    "    \n",
    "    return current_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fungsi ELM\n",
    "def Elm(particles, n_input_weights, n_hidden_node):\n",
    "    # fitness = akurasi\n",
    "    fitness = []\n",
    "\n",
    "    for i in range(len(particles)):\n",
    "        # proses elm\n",
    "        #-----------------training---------------------#\n",
    "           \n",
    "        # input weight\n",
    "        input_weights = np.array(particles[i][0:n_input_weights])\n",
    "          \n",
    "        # bias\n",
    "        biases = np.array(particles[i][n_input_weights:len(particles[i])])\n",
    "\n",
    "        # menghitung matriks keluaran hidden layer pada data training\n",
    "        hidden_layer_training = Hidden_layer(input_weights, biases, n_hidden_node, Data.dt_training)\n",
    "\n",
    "        # aktivasi hasil keluaran hidden layer data training\n",
    "        activation_training = Activation(hidden_layer_training) \n",
    "\n",
    "        # matriks moore penrose \n",
    "        pseudo_training = Pseudoinverse(activation_training)\n",
    "\n",
    "        # menghitung output weight pada data training\n",
    "        output_training = Output_weight(pseudo_training, Data.dt_target_training)\n",
    "\n",
    "        #-----------------testing--------------------#\n",
    "\n",
    "        # menghitung matriks keluaran hidden layer pada data testing\n",
    "        hidden_layer_testing = Hidden_layer(input_weights, biases, n_hidden_node, Data.dt_testing)\n",
    "\n",
    "        # aktivasi matriks keluaran hidden layer data testing\n",
    "        activation_testing = Activation(hidden_layer_testing)\n",
    "\n",
    "        # menghitung hasil prediksi pada data testing\n",
    "        prediction = Target_output(hidden_layer_testing, output_training)\n",
    "\n",
    "        # akurasi\n",
    "        accuracy = Evaluate(Data.dt_target_testing, prediction)\n",
    "        fitness.append(accuracy)\n",
    "\n",
    "    return fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Run():\n",
    "\n",
    "    # inisialisasi PSO\n",
    "    fitures = 13\n",
    "    n_hidden_node = 5 # jumlah hidden node / partikel bias\n",
    "    n_input_weights = n_hidden_node * fitures # partikel input weight\n",
    "    population = 100 # jumlah populasi pada tiap iterasi\n",
    "    max_iter = 3 # iterasi maksimum\n",
    "    w = 0.5 # bobot inersia\n",
    "    c1 = 1 # kontansta kecepatan 1\n",
    "    c2 = 1 # konstanta kecepatan 2\n",
    "\n",
    "    # data\n",
    "    Data()\n",
    "\n",
    "    # inisialisasi kecepatan awal\n",
    "    velocity_t = Velocity_0(population)\n",
    "\n",
    "    # inisialisasi posisi awal\n",
    "    particles = []\n",
    "    # perulangan sebanyak populasi\n",
    "    for pop in range(population):\n",
    "        particle = Particle(n_input_weights, n_hidden_node)\n",
    "        particles.append(particle)\n",
    "\n",
    "    # fitness tiap partikel = akurasi elm\n",
    "    fitness_t = Elm(particles, n_input_weights, n_hidden_node)\n",
    "\n",
    "    # inisialisasi Pbest\n",
    "    pbest_t = Pbest(particles, fitness_t)\n",
    "\n",
    "    # inisialisasi Gbest\n",
    "    gbest_t = Gbest(particles, fitness_t)\n",
    "\n",
    "    for iteration in range(max_iter):\n",
    "\n",
    "        # update kecepatan\n",
    "        velocity_t_1 = Velocity_update(pbest_t, gbest_t, w, c1, c2, particles, velocity_t)\n",
    "\n",
    "        # update posisi partikel\n",
    "        particles_t_1 = Position_update(particles, velocity_t_1)\n",
    "\n",
    "        # elm\n",
    "        fitness_t_1 = Elm(particles_t_1, n_input_weights, n_hidden_node)\n",
    "\n",
    "        # update pbest\n",
    "        pbest_t_1 = Pbest(particles_t_1, fitness_t_1)\n",
    "        pbest_t_1 = Comparison(pbest_t, pbest_t_1)\n",
    "\n",
    "        # update gbest\n",
    "        gbest_t_1 = Gbest(particles_t_1, fitness_t_1)\n",
    "\n",
    "        #------------------------#\n",
    "        pbest_t = pbest_t_1\n",
    "        gbest_t = gbest_t_1\n",
    "        particles = particles_t_1\n",
    "        velocity_t = velocity_t_1\n",
    "        \n",
    "    print('Input Weights')\n",
    "    print(gbest_t_1[0:n_input_weights])\n",
    "    print('')\n",
    "    print('Biases')\n",
    "    print(gbest_t_1[n_input_weights:len(gbest_t_1) - 1])\n",
    "    print('')\n",
    "    print('Accuracy')\n",
    "    print(gbest_t_1[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Input Weights\n[-0.2   0.32  0.28 -0.09 -0.68  0.77 -0.95  0.52 -0.35 -0.64  0.04  0.46\n -0.41 -0.71  0.62 -0.26 -0.68 -0.28 -0.89  0.2   0.27  0.13 -0.8  -0.74\n -0.11 -0.62 -0.34 -0.11  0.76  0.38  0.3  -0.93 -0.59  0.96 -0.79 -0.05\n  0.12 -0.3  -0.47  0.5   0.24  0.92  0.51  0.84 -0.85 -0.42  0.04  0.61\n  0.6  -0.22 -0.61  0.32  0.55  0.84 -0.15 -0.65 -0.16 -0.73  0.38  0.82\n -0.2   0.7   0.53  0.47 -0.11]\n\nBiases\n[0.29 0.47 0.45 0.18 0.83]\n\nAccuracy\n81.97\n"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    Run()"
   ]
  }
 ]
}